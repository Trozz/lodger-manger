{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a55250",
   "metadata": {},
   "source": [
    "# Legal Document Comparison and Anonymization\n",
    "A notebook to compare two legal documents and remove sensitive information like real names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca88c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41f451b6",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "We'll import the necessary Python libraries for text processing and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import difflib\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "import spacy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a27cf9",
   "metadata": {},
   "source": [
    "## Load Legal Documents\n",
    "Load the documents from text files or strings for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9098cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load a document from a text file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return \"\"\n",
    "\n",
    "# Example usage\n",
    "document1 = load_document(\"document1.txt\")\n",
    "document2 = load_document(\"document2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29d1a1d",
   "metadata": {},
   "source": [
    "## Preprocess Text\n",
    "Clean and normalize the text to ensure consistent comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize and clean text for comparison\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Process both documents\n",
    "doc1_processed = preprocess_text(document1)\n",
    "doc2_processed = preprocess_text(document2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f709ed",
   "metadata": {},
   "source": [
    "## Compare Documents for Matching\n",
    "Use difflib to compare the documents and identify differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fed427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_documents(text1: str, text2: str) -> Tuple[float, List[str]]:\n",
    "    \"\"\"\n",
    "    Compare two documents and return similarity score and differences\n",
    "    \"\"\"\n",
    "    # Calculate similarity ratio\n",
    "    similarity = difflib.SequenceMatcher(None, text1, text2).ratio()\n",
    "    \n",
    "    # Get differences\n",
    "    differ = difflib.Differ()\n",
    "    diff = list(differ.compare(text1.splitlines(), text2.splitlines()))\n",
    "    \n",
    "    return similarity, diff\n",
    "\n",
    "# Compare the processed documents\n",
    "similarity_score, differences = compare_documents(doc1_processed, doc2_processed)\n",
    "print(f\"Document similarity: {similarity_score:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b0889",
   "metadata": {},
   "source": [
    "## Identify and Remove Real Names\n",
    "Use NLP and regular expressions to identify and remove sensitive information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model for named entity recognition\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def anonymize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove personal information from text\n",
    "    \"\"\"\n",
    "    # Process text with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Replace named entities with placeholders\n",
    "    anonymized = text\n",
    "    for ent in reversed(doc.ents):\n",
    "        if ent.label_ in ['PERSON', 'ORG', 'GPE']:\n",
    "            anonymized = anonymized[:ent.start_char] + f\"[{ent.label_}]\" + anonymized[ent.end_char:]\n",
    "    \n",
    "    return anonymized\n",
    "\n",
    "# Anonymize both documents\n",
    "doc1_anonymized = anonymize_text(document1)\n",
    "doc2_anonymized = anonymize_text(document2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
